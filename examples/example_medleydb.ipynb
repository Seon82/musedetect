{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook demonstrates the usage of the `musedetect` package with the MedleyDB dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import medleydb_instruments as mdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, ExactMatch, F1Score, Precision, Recall, Specificity\n",
    "\n",
    "from musedetect.data import MedleyDBDataset, MedleyDBPreprocessor, get_all_instruments, train_test_split\n",
    "from musedetect.data.preprocess_transforms import MFCCTransform\n",
    "from musedetect.eval import compute_metrics\n",
    "from musedetect.models import CnnAudioNet\n",
    "from musedetect.training import FocalLossWithLogits, autodetect_device, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Dataset analysis for paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDB_WAV_PATH = \"/media/data/linkaband_data/mdb_split/train\"\n",
    "MDB_WAV_PATH_TEST = \"/media/data/linkaband_data/mdb_split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tracks = [file.stem for file in list(Path(MDB_WAV_PATH).glob(\"[!._]*\"))]\n",
    "dataset = list(mdb.MultiTrack(track_name) for track_name in list_tracks)\n",
    "new_dataset = [x for x in dataset if x.has_bleed is False]\n",
    "instruments = defaultdict(lambda: 0)\n",
    "for track in new_dataset:\n",
    "    for instrument in track.instruments:\n",
    "        instruments[instrument] += 1\n",
    "instruments = {k: v for k, v in sorted(instruments.items(), key=lambda item: item[1], reverse=True)}\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_context(\"paper\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "g = sns.barplot(x=list(instruments.keys()), y=np.fromiter(instruments.values(), dtype=int), color=\"b\")\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "plt.ylabel(\"Number of tracks in which the instrument appears\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = get_all_instruments()\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(levelname)s : %(message)s\", level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Create MFCC Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "To begin with, we transform the dataset of `.wav` audio files into a dataset of MFCC features. The preprocessing can be slow, so we write the MFCC features to disk instead of doing them on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = MFCCTransform(\n",
    "    origin_sample_rate=44100,  # The sample rate of the .wav files data\n",
    "    new_sample_rate=22050,  # Resample to this rate before generating the MFCC features\n",
    "    window_size=timedelta(seconds=1),  # How to split that .wav file in data points\n",
    "    stride=timedelta(seconds=0.3),  # How to split that .wav file in data points\n",
    "    n_mfcc=80,  # Number of MFCC bins\n",
    "    melkwargs={\n",
    "        \"n_mels\": 224,\n",
    "        \"n_fft\": 2048,\n",
    "        \"f_max\": 11025,\n",
    "    },  # Arguments for the STFT and the Melspectrogram generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = MedleyDBPreprocessor(transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Below, we indicate where the generated features (MFCCs) should be saved:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDB_PATH = \"/media/data/linkaband_data/mdb_split/train_features\"\n",
    "MDB_PATH_TEST = \"/media/data/linkaband_data/mdb_split/test_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    preprocessor.apply(MDB_WAV_PATH, MDB_PATH, overwrite=False)\n",
    "except FileExistsError:\n",
    "    print(\"Dataset already exists, not regenerating\")\n",
    "\n",
    "try:\n",
    "    preprocessor.apply(MDB_WAV_PATH_TEST, MDB_PATH_TEST, overwrite=False)\n",
    "except FileExistsError:\n",
    "    print(\"Test dataset already exists, not regenerating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Create pytorch Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Load the data into the pytorch dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MedleyDBDataset(MDB_PATH, hierarchy=True, class_names=instruments)\n",
    "test_data = MedleyDBDataset(MDB_PATH_TEST, hierarchy=True, class_names=instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, [0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Generate the model, and move it to the GPU if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = autodetect_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CnnAudioNet(class_num=len(data.class_names) + len(data.aggregated_class_names))\n",
    "model.to(device)\n",
    "print(f\"The moodel has {sum(p.numel() for p in model.parameters()) / 1e6:.3f} million parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=8)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Training loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weights can be used to re-weight a Cross-Entropy Loss, for instance\n",
    "freq = torch.vstack(data.labels).float().sum(0) / torch.vstack(data.labels).float().sum()\n",
    "weight = (1 / freq).to(device)\n",
    "weight = torch.nan_to_num(weight, posinf=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    epochs=12,\n",
    "    model=model,\n",
    "    loss_fn=FocalLossWithLogits(),  # nn.BCEWithLogitsLoss(weight=weight) - feel free to try out different loss functions\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    val_metrics_freq=1,  # Compute metrics on the val set every 1 epochs\n",
    "    metrics=[\n",
    "        Accuracy(task=\"multilabel\", num_labels=len(data.class_names) + len(data.aggregated_class_names)),\n",
    "        ExactMatch(task=\"multilabel\", num_labels=len(data.class_names) + len(data.aggregated_class_names)),\n",
    "        F1Score(\n",
    "            task=\"multilabel\", average=\"micro\", num_labels=len(data.class_names) + len(data.aggregated_class_names)\n",
    "        ),\n",
    "    ],\n",
    "    log_dir=\"./logs/Medley\",  # You can track the training progress using tensorboard --logdir ./logs/Medley\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Export model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"my_model_name.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Analyze result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"my_model_name.pt\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Measure the model's performance on the test set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_idx = list(range(len(data.class_names) + 1, len(data.class_names) + len(data.aggregated_class_names)))\n",
    "instrument_idx = list(range(1, len(data.class_names) + 1))\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    k: [\n",
    "        F1Score(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Precision(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Recall(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Accuracy(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        ExactMatch(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "    ]\n",
    "    for k, v in (\n",
    "        {\n",
    "            \"flat\": len(data.class_names) + len(data.aggregated_class_names),\n",
    "            \"groups\": len(group_idx),\n",
    "            \"instruments\": len(instrument_idx),\n",
    "        }\n",
    "    ).items()\n",
    "}\n",
    "\n",
    "results = compute_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    metrics=metrics,\n",
    "    groups_idx=group_idx,\n",
    "    instruments_idx=instrument_idx,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "for level in results:\n",
    "    print(level)\n",
    "    for metric, res in zip(metrics[level], results[level]):\n",
    "        print(f\"{metric.__class__.__name__}: {res.cpu().item()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_idx = list(range(len(data.class_names) + 1, len(data.class_names) + len(data.aggregated_class_names)))\n",
    "instrument_idx = list(range(1, len(data.class_names) + 1))\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    k: [\n",
    "        Accuracy(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Precision(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Recall(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Specificity(task=\"multilabel\", average=None, num_labels=v),\n",
    "        F1Score(task=\"multilabel\", average=None, num_labels=v),\n",
    "    ]\n",
    "    for k, v in (\n",
    "        {\n",
    "            \"flat\": len(data.class_names) + len(data.aggregated_class_names),\n",
    "            \"groups\": len(group_idx),\n",
    "            \"instruments\": len(instrument_idx),\n",
    "        }\n",
    "    ).items()\n",
    "}\n",
    "\n",
    "metrics = compute_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    metrics=metrics,\n",
    "    groups_idx=group_idx,\n",
    "    instruments_idx=instrument_idx,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tracks = [file.stem for file in list(Path(\"/media/data/linkaband_data/mdb_split/train\").glob(\"[!._]*\"))]\n",
    "dataset = list(mdb.MultiTrack(track_name) for track_name in list_tracks)\n",
    "new_dataset = [x for x in dataset if x.has_bleed is False]\n",
    "instrument_music_counts = {k: 0 for k in data.class_names}\n",
    "for track in new_dataset:\n",
    "    for instrument in track.instruments:\n",
    "        instrument_music_counts[instrument] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_frame_counts = torch.zeros((len(data.class_names),))\n",
    "for _, y in train_loader:\n",
    "    instrument_frame_counts += y[:, : len(data.class_names)].sum(0)\n",
    "\n",
    "test_instrument_frame_counts = torch.zeros((len(data.class_names),))\n",
    "for _, y in test_loader:\n",
    "    test_instrument_frame_counts += y[:, : len(data.class_names)].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        name: metric\n",
    "        for name, metric in zip(\n",
    "            [\n",
    "                \"accuracy\",\n",
    "                \"precision\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"f1\",\n",
    "            ],\n",
    "            np.array([x.cpu().numpy() for x in metrics[\"instruments\"]]),\n",
    "        )\n",
    "    },\n",
    "    index=np.array([\"silence\"] + list(data.class_names.keys())[1:]),\n",
    ")\n",
    "df[\"music_count\"] = instrument_music_counts.values()\n",
    "df[\"frame_count\"] = instrument_frame_counts\n",
    "df[\"test_frame_count\"] = test_instrument_frame_counts\n",
    "df[\"instrument\"] = df.index\n",
    "df = df.sort_values(\"frame_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_context(\"paper\")\n",
    "ax = sns.barplot(x=df[\"instrument\"], y=df[\"frame_count\"], color=\"b\", alpha=0.5)\n",
    "ax.set_xticklabels(g.get_xticklabels(), rotation=90)\n",
    "ax.grid(False)\n",
    "plt.ylabel(\"Number of training samples\")\n",
    "ax2 = plt.twinx()\n",
    "df_plot = df[[\"instrument\", \"precision\", \"recall\"]].melt(\"instrument\", var_name=\"Metric\", value_name=\"vals\")\n",
    "sns.lineplot(df_plot, x=\"instrument\", y=\"vals\", hue=\"Metric\", ax=ax2, linewidth=1, marker=\"o\")\n",
    "plt.xlabel(\"Instrument\")\n",
    "plt.ylabel(\"Metric value\")\n",
    "plt.title(\"Cross-entropy loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
