{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook uses `musedetec` to train hierachical models, with one model for each instrument group.\n",
    "It is more advanced: if you're just getting started, check out the simpler [example_medleydb](./example_medleydb.ipynb) notebook first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import medleydb_instruments as mdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy, ExactMatch, F1Score, Precision, Recall, Specificity, StatScores\n",
    "\n",
    "from musedetect.data import MedleyDBDataset, MedleyDBPreprocessor, get_all_instruments, train_test_split\n",
    "from musedetect.data.preprocess_transforms import MFCCTransform\n",
    "from musedetect.eval import compute_metrics\n",
    "from musedetect.models import CnnAudioNet\n",
    "from musedetect.training import autodetect_device, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDB_WAV_PATH = \"/media/data/linkaband_data/mdb_split/train\"\n",
    "MDB_WAV_PATH_TEST = \"/media/data/linkaband_data/mdb_split/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = get_all_instruments()\n",
    "\n",
    "print(instruments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\"%(levelname)s : %(message)s\", level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Create MFCC Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "To begin with, we transform the dataset of `.wav` audio files into a dataset of MFCC features. The preprocessing can be slow, so we write the MFCC features to disk instead of doing them on the fly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = MFCCTransform(\n",
    "    origin_sample_rate=44100,  # The sample rate of the .wav files data\n",
    "    new_sample_rate=22050,  # Resample to this rate before generating the MFCC features\n",
    "    window_size=timedelta(seconds=1),  # How to split that .wav file in data points\n",
    "    stride=timedelta(seconds=1),  # How to split that .wav file in data points\n",
    "    n_mfcc=80,  # Number of MFCC bins\n",
    "    melkwargs={\n",
    "        \"n_mels\": 224,\n",
    "        \"n_fft\": 2048,\n",
    "        \"f_max\": 11025,\n",
    "    },  # Arguments for the STFT and the Melspectrogram generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = MedleyDBPreprocessor(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MDB_PATH = \"/media/data/linkaband_data/mdb_split/train_features\"\n",
    "MDB_PATH_TEST = \"/media/data/linkaband_data/mdb_split/test_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    preprocessor.apply(MDB_WAV_PATH, MDB_PATH, overwrite=False)\n",
    "except FileExistsError:\n",
    "    print(\"Dataset already exists, not regenerating\")\n",
    "\n",
    "try:\n",
    "    preprocessor.apply(MDB_WAV_PATH_TEST, MDB_PATH_TEST, overwrite=False)\n",
    "except FileExistsError:\n",
    "    print(\"Test dataset already exists, not regenerating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Create pytorch Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Load the data into the pytorch dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MedleyDBDataset(MDB_PATH, hierarchy=True, class_names=instruments)\n",
    "test_data = MedleyDBDataset(MDB_PATH_TEST, hierarchy=True, class_names=instruments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "We want one dataset per model, with custom labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, root, transform, files, labels):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.load(self.root / self.files[index]).unsqueeze(0)\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from instrument group/category to idx of instruments in that category\n",
    "# idx indexes into instruments\n",
    "cat2instridx = [[] for _ in range(7)]\n",
    "for i, idx in enumerate(data.class_name_to_aggregated_idx[1:]):\n",
    "    cat2instridx[idx - 1].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, [0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(data):\n",
    "    \"\"\"\n",
    "    Generate individual datasets for each instrumental group.\n",
    "    \"\"\"\n",
    "    datasets = {\n",
    "        category: CustomDataset(data.dataset.root, data.dataset.transform, [], [])\n",
    "        for category in data.dataset.aggregated_class_names[1:]\n",
    "    }\n",
    "\n",
    "    # Only get labels from the subset\n",
    "    labels = torch.vstack(data.dataset.labels)[data.indices]\n",
    "    instr_labels = labels[:, 1 : len(data.dataset.class_names)]\n",
    "    class_labels = labels[:, len(data.dataset.class_names) :]\n",
    "\n",
    "    # Only get files from the subset\n",
    "    files = np.array(data.dataset.files)[data.indices]\n",
    "\n",
    "    for i, cat_name in enumerate(datasets.keys()):\n",
    "        dataset_labels = instr_labels[:, cat2instridx[i]]\n",
    "        datasets[cat_name].labels = dataset_labels\n",
    "        datasets[cat_name].files = files.tolist()\n",
    "\n",
    "    # Add dataset for the first tree leve, aka instrument groups\n",
    "    datasets[\"global\"] = CustomDataset(\n",
    "        data.dataset.root,\n",
    "        data.dataset.transform,\n",
    "        files=files,\n",
    "        labels=class_labels,\n",
    "    )\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "train_datasets = generate_datasets(train_data)\n",
    "val_datasets = generate_datasets(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Generate the model, and move it to the GPU if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = autodetect_device()\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding doesn't guarantee deterministic results, possibly because of nondeterministic GPU operations\n",
    "# torch.random.manual_seed(42)\n",
    "\n",
    "# Configure number of training epochs per model\n",
    "epochs_per_model = {\n",
    "    \"11 Struck idiophones\": 10,\n",
    "    \"21 Struck membranophones\": 15,\n",
    "    \"31 Simple chordophones\": 15,\n",
    "    \"32 Composite chordophones\": 15,\n",
    "    \"41 Free aerophones\": 15,\n",
    "    \"42 Non-free aerophones\": 15,\n",
    "    \"53 Radioelectric instruments\": 15,\n",
    "    \"global\": 15,\n",
    "}\n",
    "\n",
    "for cat_name, epoch_num in epochs_per_model.items():\n",
    "    print(f\"Training on {cat_name}\")\n",
    "    local_train_data = train_datasets[cat_name]\n",
    "    local_val_data = val_datasets[cat_name] if val_datasets else None\n",
    "\n",
    "    model = CnnAudioNet(len(local_train_data.labels[0]))\n",
    "    model.to(device)\n",
    "    train_loader = DataLoader(local_train_data, batch_size=batch_size, prefetch_factor=2, num_workers=3)\n",
    "    val_loader = (\n",
    "        DataLoader(local_val_data, batch_size=batch_size, shuffle=False, num_workers=3) if local_val_data else None\n",
    "    )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    num_labels = len(local_train_data.labels[0])\n",
    "\n",
    "    train(\n",
    "        epochs=epoch_num,\n",
    "        model=model,\n",
    "        loss_fn=nn.BCEWithLogitsLoss(),  # FocalLossWithLogits(),\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        val_metrics_freq=1,\n",
    "        metrics=[\n",
    "            F1Score(task=\"multilabel\", average=\"micro\", num_labels=num_labels),\n",
    "            Precision(task=\"multilabel\", num_labels=num_labels),\n",
    "            Recall(task=\"multilabel\", num_labels=num_labels),\n",
    "        ]\n",
    "        if num_labels > 1\n",
    "        else [],\n",
    "        log_dir=\"./logs/Medley\",\n",
    "        quiet=False,\n",
    "    )\n",
    "    torch.save(model, f\"multi_{cat_name}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {cat: torch.load(f\"multi_{cat}.pt\") for cat in train_datasets}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Build the giant hierarchical model by combining smaller models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperModel(nn.Module):\n",
    "    def __init__(self, models, cat2idx):\n",
    "        super().__init__()\n",
    "        self.models = models.copy()\n",
    "        self.global_model = self.models.pop(\"global\")\n",
    "        self.cat2idx = cat2idx\n",
    "        self.instr_len = max(max(x) for x in self.cat2idx)\n",
    "        self.total_length = self.instr_len + 1 + len(self.cat2idx) + 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = torch.zeros(x.shape[0], self.total_length, device=x.device)\n",
    "        global_res = self.global_model(\n",
    "            x\n",
    "        )  # +1 for initial silence instrument, +1 to start the step after the last instrument\n",
    "        res[:, self.instr_len + 2 :] = torch.sigmoid(global_res)\n",
    "\n",
    "        for i, model in enumerate(self.models.values()):\n",
    "            y = model(x)\n",
    "            res[:, torch.tensor(self.cat2idx[i]) + 1] = torch.sigmoid(y)  # * global_res[:, i + 1, None]\n",
    "\n",
    "        res[:, 0] = res[:, self.instr_len + 1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SuperModel(models, cat2instridx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Analyze result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_idx = list(range(len(data.class_names), len(data.class_names) + len(data.aggregated_class_names)))\n",
    "instrument_idx = list(range(len(data.class_names)))\n",
    "\n",
    "metric_values = {\n",
    "    k: [\n",
    "        F1Score(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Precision(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Recall(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Accuracy(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        ExactMatch(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "    ]\n",
    "    for k, v in (\n",
    "        {\n",
    "            \"flat\": len(data.class_names + data.aggregated_class_names),\n",
    "            \"groups\": len(group_idx),\n",
    "            \"instruments\": len(instrument_idx),\n",
    "        }\n",
    "    ).items()\n",
    "}\n",
    "\n",
    "results = compute_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    metrics=metric_values,\n",
    "    groups_idx=group_idx,\n",
    "    instruments_idx=instrument_idx,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "for level in results:\n",
    "    print(level)\n",
    "    for metric, res in zip(metric_values[level], results[level]):\n",
    "        print(f\"{metric.__class__.__name__}: {res.cpu().item()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_idx = list(range(len(data.class_names), len(data.class_names) + len(data.aggregated_class_names)))\n",
    "instrument_idx = list(range(len(data.class_names)))\n",
    "\n",
    "\n",
    "metric_values = {\n",
    "    k: [\n",
    "        Accuracy(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Precision(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Recall(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Specificity(task=\"multilabel\", average=None, num_labels=v),\n",
    "        F1Score(task=\"multilabel\", average=None, num_labels=v),\n",
    "        StatScores(task=\"multilabel\", average=None, num_labels=v),\n",
    "        Precision(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        Recall(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "        F1Score(task=\"multilabel\", average=\"micro\", num_labels=v),\n",
    "    ]\n",
    "    for k, v in (\n",
    "        {\n",
    "            \"flat\": len(data.class_names) + len(data.aggregated_class_names),\n",
    "            \"groups\": len(group_idx),\n",
    "            \"instruments\": len(instrument_idx),\n",
    "        }\n",
    "    ).items()\n",
    "}\n",
    "\n",
    "results = compute_metrics(\n",
    "    model,\n",
    "    test_loader,\n",
    "    device,\n",
    "    metrics=metric_values,\n",
    "    groups_idx=group_idx,\n",
    "    instruments_idx=instrument_idx,\n",
    ")\n",
    "\n",
    "for level in results:\n",
    "    print(level)\n",
    "    for metric, res in zip(metric_values[level][-3:], results[level][-3:]):\n",
    "        print(f\"{metric.__class__.__name__}: {res.cpu().item()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = results[\"instruments\"][-4].cpu()  # StatsScore\n",
    "df_conf = pd.DataFrame(\n",
    "    data=conf_mat,\n",
    "    index=np.array(instruments),\n",
    "    columns=[\"TP\", \"FP\", \"TN\", \"FN\", \"Support\"],\n",
    ")\n",
    "# df_conf = df_conf.drop(columns=\"Support\")\n",
    "# df_conf[\"Precision\"] = results[\"instruments\"][1].cpu()[in_train]\n",
    "# df_conf[\"Recall\"] = results[\"instruments\"][2].cpu()[in_train]\n",
    "df_conf[\"FP rate\"] = df_conf[\"FP\"] / (df_conf[\"FP\"] + df_conf[\"TN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from musedetect.data.medleydb import hornbostel_sachs\n",
    "\n",
    "list_tracks = [file.stem for file in list(Path(\"/media/data/linkaband_data/mdb_split/train\").glob(\"[!._]*\"))]\n",
    "dataset = list(mdb.MultiTrack(track_name) for track_name in list_tracks)\n",
    "new_dataset = [x for x in dataset if x.has_bleed is False]\n",
    "instrument_music_counts = {k: 0 for k in data.class_names}\n",
    "for track in new_dataset:\n",
    "    for instrument in track.instruments:\n",
    "        instrument_music_counts[instrument] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_frame_counts = torch.zeros((len(data.class_names),))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "for _, y in train_loader:\n",
    "    instrument_frame_counts += y[:, : len(data.class_names)].sum(0)\n",
    "\n",
    "test_instrument_frame_counts = torch.zeros((len(data.class_names),))\n",
    "for _, y in test_loader:\n",
    "    test_instrument_frame_counts += y[:, : len(data.class_names)].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        name: metric\n",
    "        for name, metric in zip(\n",
    "            [\n",
    "                \"accuracy\",\n",
    "                \"precision\",\n",
    "                \"recall\",\n",
    "                \"specificity\",\n",
    "                \"f1\",\n",
    "            ],\n",
    "            np.array([x.cpu().numpy() for x in results[\"instruments\"][:5]]),\n",
    "        )\n",
    "    },\n",
    "    index=np.array([\"silence\"] + data.class_names[1:]),\n",
    ")\n",
    "df[\"music_count\"] = instrument_music_counts.values()\n",
    "df[\"frame_count\"] = instrument_frame_counts\n",
    "df[\"test_frame_count\"] = test_instrument_frame_counts\n",
    "df[\"instrument\"] = df.index\n",
    "df[\"group\"] = df.instrument.apply(lambda x: hornbostel_sachs(x) if x != \"silence\" else \"Silence\")\n",
    "df = df.sort_values(\"frame_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=sns.color_palette()[0], label=\"Train\", alpha=0.5),\n",
    "    Patch(facecolor=sns.color_palette()[1], label=\"Test\", alpha=0.5),\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", label=\"Precision\", linewidth=0, markerfacecolor=sns.color_palette()[2]),\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", label=\"Recall\", linewidth=0, markerfacecolor=sns.color_palette()[3]),\n",
    "]\n",
    "\n",
    "\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_context(\"paper\")\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"grid.color\"] = \"black\"\n",
    "\n",
    "fit, ax = plt.subplots(figsize=(6, 15))\n",
    "plt.xlim((-0.01, 1.0))\n",
    "plt.ylabel(\"Instruments\")\n",
    "plt.xlabel(\"Score\")\n",
    "ax.grid(axis=\"y\", visible=False)\n",
    "\n",
    "ax_bar = ax.twiny()\n",
    "plt.xlabel(\"Number of samples\")\n",
    "\n",
    "ax_scatter = ax.twiny()\n",
    "\n",
    "\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "ax_bar.xaxis.set_label_position(\"bottom\")\n",
    "ax_bar.xaxis.tick_bottom()\n",
    "ax_bar.grid(False)\n",
    "\n",
    "ax_scatter.tick_params(axis=\"x\", top=False, bottom=False, labeltop=False, labelbottom=False)\n",
    "ax_scatter.grid(False)\n",
    "\n",
    "# Plot frame count for training and test data\n",
    "sns.barplot(\n",
    "    data=pd.DataFrame(\n",
    "        {\n",
    "            \"instrument\": df.instrument.tolist() * 2,\n",
    "            \"frame_count\": df.frame_count.tolist() + df.test_frame_count.tolist(),\n",
    "            \"Data split\": [\"train\"] * len(df.frame_count) + [\"test\"] * len(df.test_frame_count),\n",
    "        }\n",
    "    ),\n",
    "    y=\"instrument\",\n",
    "    x=\"frame_count\",\n",
    "    hue=\"Data split\",\n",
    "    alpha=0.5,\n",
    "    dodge=False,\n",
    "    legend=False,\n",
    "    ax=ax_bar,\n",
    ")\n",
    "\n",
    "\n",
    "ylim = ax_bar.get_ylim()\n",
    "plt.ylim(ylim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "df_plot = df[[\"instrument\", \"precision\", \"recall\"]].melt(\"instrument\", var_name=\"Metric\", value_name=\"vals\")\n",
    "for i in range(len(df.precision)):\n",
    "    colors = {\"precision\": sns.color_palette()[2], \"recall\": sns.color_palette()[3]}\n",
    "    if df.precision.iloc[i] > df.recall.iloc[i]:\n",
    "        col1, col2 = (\"precision\", \"recall\")\n",
    "    else:\n",
    "        col1, col2 = (\"recall\", \"precision\")\n",
    "    plt.plot([-1, df[col2].iloc[i]], [i, i], color=colors[col2], linestyle=\"-\", linewidth=0.5, zorder=0)\n",
    "    plt.plot(\n",
    "        [df[col2].iloc[i], df[col1].iloc[i]],\n",
    "        [i, i],\n",
    "        color=colors[col1],\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "        zorder=0,\n",
    "    )\n",
    "sns.scatterplot(\n",
    "    df_plot,\n",
    "    y=\"instrument\",\n",
    "    x=\"vals\",\n",
    "    hue=\"Metric\",\n",
    "    ax=ax_scatter,\n",
    "    linewidth=1,\n",
    "    marker=\"o\",\n",
    "    palette=sns.color_palette()[2:],\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlim(xlim)\n",
    "\n",
    "\n",
    "plt.legend(title=\"Category\", handles=legend_elements, loc=(0.7, 0.01))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            name: metric\n",
    "            for name, metric in zip(\n",
    "                [\n",
    "                    \"accuracy\",\n",
    "                    \"precision\",\n",
    "                    \"recall\",\n",
    "                    \"specificity\",\n",
    "                    \"f1\",\n",
    "                ],\n",
    "                np.array([x.cpu().numpy() for x in results[\"groups\"][:5]]),\n",
    "            )\n",
    "        },\n",
    "        index=np.array([\"Silence\"] + data.aggregated_class_names[1:]),\n",
    "    )\n",
    "    .reset_index(names=\"group\")\n",
    "    .sort_values(\"group\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_group[[\"frame_count\", \"test_frame_count\"]] = (\n",
    "    df.groupby(\"group\")[[\"frame_count\", \"test_frame_count\"]].sum().sort_values(\"group\").reset_index(drop=True)\n",
    ")\n",
    "df_group = df_group.sort_values(\"frame_count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=sns.color_palette()[0], label=\"Train\", alpha=0.5),\n",
    "    Patch(facecolor=sns.color_palette()[1], label=\"Test\", alpha=0.5),\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", label=\"Precision\", linewidth=0, markerfacecolor=sns.color_palette()[2]),\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", label=\"Recall\", linewidth=0, markerfacecolor=sns.color_palette()[3]),\n",
    "]\n",
    "\n",
    "\n",
    "sns.set_theme(\"paper\")\n",
    "sns.set_context(\"paper\")\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "mpl.rcParams[\"grid.color\"] = \"f1f1f5\"\n",
    "\n",
    "\n",
    "fit, ax = plt.subplots(figsize=(8, 5))\n",
    "plt.ylabel(\"Groups\")\n",
    "plt.xlabel(\"Score\")\n",
    "ax.grid(axis=\"y\", visible=False)\n",
    "\n",
    "ax_bar = ax.twiny()\n",
    "plt.xlabel(\"Number of samples\")\n",
    "\n",
    "ax_scatter = ax.twiny()\n",
    "\n",
    "\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "ax_bar.xaxis.set_label_position(\"bottom\")\n",
    "ax_bar.xaxis.tick_bottom()\n",
    "ax_bar.grid(False)\n",
    "\n",
    "ax_scatter.tick_params(axis=\"x\", top=False, bottom=False, labeltop=False, labelbottom=False)\n",
    "ax_scatter.grid(False)\n",
    "\n",
    "sns.barplot(\n",
    "    data=pd.DataFrame(\n",
    "        {\n",
    "            \"group\": df_group.group.tolist() * 2,\n",
    "            \"frame_count\": df_group.frame_count.tolist() + df_group.test_frame_count.tolist(),\n",
    "            \"Data split\": [\"train\"] * len(df_group.frame_count) + [\"test\"] * len(df_group.test_frame_count),\n",
    "        }\n",
    "    ),\n",
    "    y=\"group\",\n",
    "    x=\"frame_count\",\n",
    "    hue=\"Data split\",\n",
    "    alpha=0.5,\n",
    "    dodge=False,\n",
    "    legend=False,\n",
    "    ax=ax_bar,\n",
    ")\n",
    "\n",
    "\n",
    "ylim = ax_bar.get_ylim()\n",
    "plt.ylim(ylim)\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "df_group_plot = df_group[[\"group\", \"precision\", \"recall\"]].melt(\"group\", var_name=\"Metric\", value_name=\"vals\")\n",
    "for i in range(len(df_group.precision)):\n",
    "    colors = {\"precision\": sns.color_palette()[2], \"recall\": sns.color_palette()[3]}\n",
    "    if df_group.precision.iloc[i] > df_group.recall.iloc[i]:\n",
    "        col1, col2 = (\"precision\", \"recall\")\n",
    "    else:\n",
    "        col1, col2 = (\"recall\", \"precision\")\n",
    "    plt.plot([-1, df_group[col2].iloc[i]], [i, i], color=colors[col2], linestyle=\"-\", linewidth=0.5, zorder=0)\n",
    "    plt.plot(\n",
    "        [df_group[col2].iloc[i], df_group[col1].iloc[i]],\n",
    "        [i, i],\n",
    "        color=colors[col1],\n",
    "        linestyle=\"-\",\n",
    "        linewidth=0.5,\n",
    "        zorder=0,\n",
    "    )\n",
    "sns.scatterplot(\n",
    "    df_group_plot,\n",
    "    y=\"group\",\n",
    "    x=\"vals\",\n",
    "    hue=\"Metric\",\n",
    "    ax=ax_scatter,\n",
    "    linewidth=1,\n",
    "    marker=\"o\",\n",
    "    palette=sns.color_palette()[2:],\n",
    "    legend=False,\n",
    ")\n",
    "plt.xlim(xlim)\n",
    "\n",
    "\n",
    "plt.legend(title=\"Category\", handles=legend_elements, loc=(0.8, 0.27))\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
